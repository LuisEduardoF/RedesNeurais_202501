{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61015e7c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Chest X-ray Dataset\n",
    "\n",
    "Análise exploratória da base de dados [Chest X-ray Image (COVID19, PNEUMONIA, and NORMAL)](https://www.kaggle.com/datasets/alsaniipe/chest-x-ray-image) para o Trabalho 2 de Redes Neurais.\n",
    "\n",
    "Este notebook irá:\n",
    "1. Verificar a estrutura do dataset\n",
    "2. Analisar a distribuição das classes\n",
    "3. Examinar características das imagens (dimensões, formato, canais)\n",
    "4. Visualizar exemplos de imagens de cada classe\n",
    "5. Identificar possíveis problemas ou desafios no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms import v2\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Para visualizar as imagens no notebook\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084eefb6",
   "metadata": {},
   "source": [
    "## 1. Configuração e Download do Dataset\n",
    "\n",
    "Primeiro, vamos configurar os caminhos para o dataset e verificar se ele já está disponível localmente ou se precisamos fazer o download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f704cfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kagglehub não está instalado. Tentando instalar...\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: packaging in /home/luiscamara/RedesNeurais_202501/RedesNeurais/lib/python3.10/site-packages (from kagglehub) (25.0)\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.7.9-py3-none-any.whl (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: urllib3, tqdm, pyyaml, idna, charset_normalizer, certifi, requests, kagglehub\n",
      "Successfully installed certifi-2025.7.9 charset_normalizer-3.4.2 idna-3.10 kagglehub-0.3.12 pyyaml-6.0.2 requests-2.32.4 tqdm-4.67.1 urllib3-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luiscamara/RedesNeurais_202501/RedesNeurais/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m         KAGGLE_AVAILABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Definir caminhos do dataset\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m BASE_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/luiscamara/RedesNeurais_202501/Trabalho2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m DATA_PATH \u001b[38;5;241m=\u001b[39m BASE_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Verificar se o diretório de dados existe\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Importar a biblioteca para download do Kaggle\n",
    "try:\n",
    "    import kagglehub\n",
    "    KAGGLE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"kagglehub não está instalado. Tentando instalar...\")\n",
    "    !pip install kagglehub\n",
    "    try:\n",
    "        import kagglehub\n",
    "        KAGGLE_AVAILABLE = True\n",
    "    except ImportError:\n",
    "        print(\"Falha ao instalar kagglehub. Dataset deverá estar disponível localmente.\")\n",
    "        KAGGLE_AVAILABLE = False\n",
    "\n",
    "# Definir caminhos do dataset\n",
    "BASE_PATH = Path('/home/luiscamara/RedesNeurais_202501/Trabalho2')\n",
    "DATA_PATH = BASE_PATH / 'data'\n",
    "\n",
    "# Verificar se o diretório de dados existe\n",
    "if not DATA_PATH.exists():\n",
    "    os.makedirs(DATA_PATH, exist_ok=True)\n",
    "    \n",
    "# Dataset ID do Kaggle\n",
    "DATASET_ID = \"alsaniipe/chest-x-ray-image\"\n",
    "\n",
    "# Função para download do dataset\n",
    "def download_dataset():\n",
    "    if KAGGLE_AVAILABLE:\n",
    "        print(\"Iniciando download do dataset do Kaggle...\")\n",
    "        try:\n",
    "            kagglehub.init()\n",
    "            kagglehub.dataset_download(DATASET_ID, DATA_PATH)\n",
    "            print(f\"Dataset baixado com sucesso para {DATA_PATH}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao baixar o dataset: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"kagglehub não está disponível. O download não será realizado.\")\n",
    "        return False\n",
    "\n",
    "# Verificar se o dataset já está disponível localmente\n",
    "dataset_dirs = ['chest_xray_train', 'chest_xray_test']\n",
    "dataset_available = all((DATA_PATH / dir_name).exists() for dir_name in dataset_dirs)\n",
    "\n",
    "if not dataset_available:\n",
    "    print(\"Dataset não encontrado localmente. Tentando baixar...\")\n",
    "    download_success = download_dataset()\n",
    "    if not download_success:\n",
    "        print(\"Não foi possível baixar o dataset. Por favor, baixe manualmente do Kaggle e extraia para o diretório de dados.\")\n",
    "else:\n",
    "    print(f\"Dataset já está disponível em {DATA_PATH}\")\n",
    "\n",
    "# Configurar caminhos para os conjuntos de treino e teste\n",
    "TRAIN_PATH = DATA_PATH / 'chest_xray_train'\n",
    "TEST_PATH = DATA_PATH / 'chest_xray_test'\n",
    "\n",
    "# Verificar se os diretórios existem\n",
    "print(f\"Diretório de treino existe: {TRAIN_PATH.exists()}\")\n",
    "print(f\"Diretório de teste existe: {TEST_PATH.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d73b6a",
   "metadata": {},
   "source": [
    "## 2. Análise da Estrutura do Dataset\n",
    "\n",
    "Vamos examinar a estrutura do dataset, incluindo a quantidade de imagens em cada classe (COVID-19, Pneumonia, Normal) nos conjuntos de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425daea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para contar imagens por classe\n",
    "def count_images_in_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    return len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and \n",
    "               (f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png'))])\n",
    "\n",
    "# Classes disponíveis no dataset\n",
    "classes = ['COVID19', 'NORMAL', 'PNEUMONIA']\n",
    "\n",
    "# Contar imagens por classe nos conjuntos de treino e teste\n",
    "train_counts = {}\n",
    "test_counts = {}\n",
    "\n",
    "for cls in classes:\n",
    "    train_dir = os.path.join(TRAIN_PATH, cls)\n",
    "    test_dir = os.path.join(TEST_PATH, cls)\n",
    "    \n",
    "    train_count = count_images_in_directory(train_dir)\n",
    "    test_count = count_images_in_directory(test_dir)\n",
    "    \n",
    "    train_counts[cls] = train_count\n",
    "    test_counts[cls] = test_count\n",
    "    \n",
    "    print(f\"Classe {cls}:\")\n",
    "    print(f\"  - Treino: {train_count} imagens\")\n",
    "    print(f\"  - Teste: {test_count} imagens\")\n",
    "\n",
    "# Total de imagens\n",
    "total_train = sum(train_counts.values())\n",
    "total_test = sum(test_counts.values())\n",
    "total_images = total_train + total_test\n",
    "\n",
    "print(f\"\\nTotal de imagens:\")\n",
    "print(f\"  - Treino: {total_train}\")\n",
    "print(f\"  - Teste: {total_test}\")\n",
    "print(f\"  - Total: {total_images}\")\n",
    "\n",
    "# Criar DataFrames para visualização\n",
    "train_df = pd.DataFrame(list(train_counts.items()), columns=['Classe', 'Contagem'])\n",
    "train_df['Conjunto'] = 'Treino'\n",
    "\n",
    "test_df = pd.DataFrame(list(test_counts.items()), columns=['Classe', 'Contagem'])\n",
    "test_df['Conjunto'] = 'Teste'\n",
    "\n",
    "# Combinar os DataFrames\n",
    "data_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Verificar desbalanceamento de classes\n",
    "print(\"\\nDistribuição percentual no conjunto de treino:\")\n",
    "for cls in classes:\n",
    "    percentage = (train_counts[cls] / total_train) * 100\n",
    "    print(f\"  - {cls}: {percentage:.2f}%\")\n",
    "\n",
    "print(\"\\nDistribuição percentual no conjunto de teste:\")\n",
    "for cls in classes:\n",
    "    percentage = (test_counts[cls] / total_test) * 100\n",
    "    print(f\"  - {cls}: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d7373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuição de classes\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Gráfico de barras para o conjunto de treino\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Classe', y='Contagem', data=train_df, palette='viridis')\n",
    "plt.title('Distribuição de Classes no Conjunto de Treino')\n",
    "plt.ylabel('Número de Imagens')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico de barras para o conjunto de teste\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Classe', y='Contagem', data=test_df, palette='viridis')\n",
    "plt.title('Distribuição de Classes no Conjunto de Teste')\n",
    "plt.ylabel('Número de Imagens')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de pizza para visualizar a proporção de cada classe no conjunto de treino\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Treino\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie([train_counts[cls] for cls in classes], labels=classes, autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "plt.title('Proporção de Classes no Conjunto de Treino')\n",
    "\n",
    "# Teste\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie([test_counts[cls] for cls in classes], labels=classes, autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "plt.title('Proporção de Classes no Conjunto de Teste')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c269bd6",
   "metadata": {},
   "source": [
    "## 3. Análise das Características das Imagens\n",
    "\n",
    "Vamos examinar as características das imagens, como dimensões (altura e largura), formato (RGB ou escala de cinza), e bits por pixel. Isso ajudará a definir o pré-processamento adequado para o treinamento das redes neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3c7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar a imagem usando a função recomendada na especificação\n",
    "def load_img(path):\n",
    "    # Le a imagem em diversos formatos e garante que a imagem tenha 3 canais\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    # converte para um tensor do pytorch\n",
    "    img = v2.functional.to_image(img)\n",
    "    # garante que seja uma imagem de 8 bits reescalando os valores adequadamente\n",
    "    img = v2.functional.to_dtype(img, dtype=torch.uint8, scale=True)\n",
    "    return img\n",
    "\n",
    "# Função para analisar características de uma amostra de imagens\n",
    "def analyze_image_characteristics(directory, sample_size=20):\n",
    "    image_files = []\n",
    "    \n",
    "    # Coletar todos os arquivos de imagem no diretório\n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(directory, cls)\n",
    "        if os.path.exists(class_dir):\n",
    "            files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) \n",
    "                     if os.path.isfile(os.path.join(class_dir, f)) and \n",
    "                     (f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png'))]\n",
    "            image_files.extend([(f, cls) for f in files])\n",
    "    \n",
    "    # Amostrar aleatoriamente\n",
    "    if len(image_files) > sample_size:\n",
    "        image_files = random.sample(image_files, sample_size)\n",
    "    \n",
    "    # Características para análise\n",
    "    widths = []\n",
    "    heights = []\n",
    "    aspect_ratios = []\n",
    "    channels = []\n",
    "    formats = []\n",
    "    bit_depths = []\n",
    "    file_sizes = []\n",
    "    classes_list = []\n",
    "    \n",
    "    # Analisar cada imagem\n",
    "    for file_path, cls in tqdm(image_files, desc=\"Analisando imagens\"):\n",
    "        try:\n",
    "            # Informações básicas do arquivo\n",
    "            file_size = os.path.getsize(file_path) / 1024  # em KB\n",
    "            file_sizes.append(file_size)\n",
    "            \n",
    "            # Abrir imagem com PIL\n",
    "            with Image.open(file_path) as img:\n",
    "                width, height = img.size\n",
    "                format_img = img.format\n",
    "                mode = img.mode\n",
    "                \n",
    "                widths.append(width)\n",
    "                heights.append(height)\n",
    "                aspect_ratios.append(width / height)\n",
    "                formats.append(format_img)\n",
    "                \n",
    "                # Determinar número de canais\n",
    "                if mode == 'RGB':\n",
    "                    channels.append(3)\n",
    "                elif mode == 'RGBA':\n",
    "                    channels.append(4)\n",
    "                elif mode == 'L':\n",
    "                    channels.append(1)\n",
    "                else:\n",
    "                    channels.append(None)\n",
    "                \n",
    "                # Determinar bits por pixel\n",
    "                if hasattr(img, 'bits'):\n",
    "                    bit_depths.append(img.bits)\n",
    "                else:\n",
    "                    if mode in ['RGB', 'RGBA', 'L']:\n",
    "                        bit_depths.append(8)  # Default para muitos formatos\n",
    "                    else:\n",
    "                        bit_depths.append(None)\n",
    "            \n",
    "            classes_list.append(cls)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao analisar {file_path}: {e}\")\n",
    "    \n",
    "    # Criar DataFrame com as características\n",
    "    data = {\n",
    "        'Classe': classes_list,\n",
    "        'Largura': widths,\n",
    "        'Altura': heights,\n",
    "        'Proporção': aspect_ratios,\n",
    "        'Canais': channels,\n",
    "        'Formato': formats,\n",
    "        'Bits': bit_depths,\n",
    "        'Tamanho (KB)': file_sizes\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Analisar imagens do conjunto de treino\n",
    "print(\"Analisando imagens do conjunto de treino...\")\n",
    "train_images_df = analyze_image_characteristics(TRAIN_PATH, sample_size=50)\n",
    "\n",
    "# Exibir estatísticas das imagens\n",
    "print(\"\\nEstatísticas das imagens de treino:\")\n",
    "print(train_images_df.describe())\n",
    "\n",
    "# Exibir informações específicas por classe\n",
    "print(\"\\nEstatísticas por classe:\")\n",
    "print(train_images_df.groupby('Classe').agg({\n",
    "    'Largura': ['mean', 'min', 'max'],\n",
    "    'Altura': ['mean', 'min', 'max'],\n",
    "    'Proporção': ['mean', 'min', 'max'],\n",
    "    'Canais': pd.Series.mode,\n",
    "    'Bits': pd.Series.mode,\n",
    "    'Tamanho (KB)': ['mean', 'min', 'max']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar a distribuição de dimensões das imagens\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Histograma das larguras\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(train_images_df['Largura'], bins=20, kde=True)\n",
    "plt.title('Distribuição de Larguras')\n",
    "plt.xlabel('Largura (pixels)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma das alturas\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(train_images_df['Altura'], bins=20, kde=True)\n",
    "plt.title('Distribuição de Alturas')\n",
    "plt.xlabel('Altura (pixels)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma das proporções\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(train_images_df['Proporção'], bins=20, kde=True)\n",
    "plt.title('Distribuição de Proporções (Largura/Altura)')\n",
    "plt.xlabel('Proporção')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma dos tamanhos de arquivo\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(train_images_df['Tamanho (KB)'], bins=20, kde=True)\n",
    "plt.title('Distribuição de Tamanhos de Arquivo')\n",
    "plt.xlabel('Tamanho (KB)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizar a relação entre largura e altura\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=train_images_df, x='Largura', y='Altura', hue='Classe', alpha=0.7)\n",
    "plt.title('Relação entre Largura e Altura por Classe')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Contagem de canais e formatos\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Contagem de canais\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='Canais', data=train_images_df, palette='viridis')\n",
    "plt.title('Distribuição de Canais')\n",
    "plt.xlabel('Número de Canais')\n",
    "plt.ylabel('Contagem')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Contagem de formatos\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='Formato', data=train_images_df, palette='viridis')\n",
    "plt.title('Distribuição de Formatos')\n",
    "plt.xlabel('Formato')\n",
    "plt.ylabel('Contagem')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot das dimensões por classe\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Boxplot das larguras por classe\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='Classe', y='Largura', data=train_images_df, palette='viridis')\n",
    "plt.title('Distribuição de Larguras por Classe')\n",
    "plt.ylabel('Largura (pixels)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Boxplot das alturas por classe\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='Classe', y='Altura', data=train_images_df, palette='viridis')\n",
    "plt.title('Distribuição de Alturas por Classe')\n",
    "plt.ylabel('Altura (pixels)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedd357",
   "metadata": {},
   "source": [
    "## 4. Visualização de Exemplos de Imagens por Classe\n",
    "\n",
    "Vamos visualizar exemplos de imagens de cada classe (COVID-19, Pneumonia, Normal) para entender melhor as características visuais que as redes neurais precisarão aprender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3023730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter exemplos de imagens de cada classe\n",
    "def get_example_images(directory, n_examples=3):\n",
    "    examples = {}\n",
    "    \n",
    "    for cls in classes:\n",
    "        class_dir = os.path.join(directory, cls)\n",
    "        if os.path.exists(class_dir):\n",
    "            files = [os.path.join(class_dir, f) for f in os.listdir(class_dir) \n",
    "                     if os.path.isfile(os.path.join(class_dir, f)) and \n",
    "                     (f.endswith('.jpg') or f.endswith('.jpeg') or f.endswith('.png'))]\n",
    "            \n",
    "            if len(files) > n_examples:\n",
    "                files = random.sample(files, n_examples)\n",
    "            \n",
    "            examples[cls] = files\n",
    "    \n",
    "    return examples\n",
    "\n",
    "# Obter exemplos de imagens do conjunto de treino\n",
    "print(\"Obtendo exemplos de imagens...\")\n",
    "train_examples = get_example_images(TRAIN_PATH, n_examples=4)\n",
    "\n",
    "# Função para mostrar exemplos de imagens\n",
    "def show_examples(examples):\n",
    "    n_classes = len(classes)\n",
    "    n_examples = len(examples[classes[0]])\n",
    "    \n",
    "    plt.figure(figsize=(15, 5*n_classes))\n",
    "    \n",
    "    for i, cls in enumerate(classes):\n",
    "        for j, img_path in enumerate(examples[cls]):\n",
    "            plt.subplot(n_classes, n_examples, i*n_examples + j + 1)\n",
    "            \n",
    "            try:\n",
    "                # Carregar imagem com a função recomendada\n",
    "                img_tensor = load_img(img_path)\n",
    "                img_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "                \n",
    "                plt.imshow(img_np)\n",
    "                plt.title(f'{cls} - Exemplo {j+1}')\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # Mostrar dimensões e formato\n",
    "                img_pil = Image.open(img_path)\n",
    "                plt.xlabel(f'{img_pil.size[0]}x{img_pil.size[1]}, {img_pil.mode}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                plt.text(0.5, 0.5, f\"Erro: {str(e)}\", ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar exemplos de imagens\n",
    "show_examples(train_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5586751d",
   "metadata": {},
   "source": [
    "## 5. Visualização de Pré-processamento e Data Augmentation\n",
    "\n",
    "Vamos testar algumas transformações de pré-processamento e data augmentation que poderão ser utilizadas no treinamento das redes neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf861fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar uma imagem para testar as transformações\n",
    "sample_cls = random.choice(classes)\n",
    "sample_img_path = train_examples[sample_cls][0]\n",
    "print(f\"Imagem selecionada: {sample_img_path}\")\n",
    "\n",
    "# Carregar a imagem\n",
    "sample_img_tensor = load_img(sample_img_path)\n",
    "sample_img_np = sample_img_tensor.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Definir transformações de pré-processamento básicas\n",
    "preprocess_transforms = v2.Compose([\n",
    "    v2.Resize((224, 224)),  # Redimensionar para 224x224 (comum para muitas CNNs)\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)  # Normalizar para [0, 1]\n",
    "])\n",
    "\n",
    "# Aplicar pré-processamento básico\n",
    "preprocessed_img = preprocess_transforms(sample_img_tensor)\n",
    "preprocessed_img_np = preprocessed_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Definir transformações de data augmentation\n",
    "augment_transforms = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=15),\n",
    "    v2.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "# Aplicar data augmentation várias vezes\n",
    "n_augmentations = 8\n",
    "augmented_imgs = [augment_transforms(sample_img_tensor) for _ in range(n_augmentations)]\n",
    "augmented_imgs_np = [img.permute(1, 2, 0).numpy() for img in augmented_imgs]\n",
    "\n",
    "# Visualizar imagem original, pré-processada e aumentada\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Imagem original\n",
    "plt.subplot(2, 5, 1)\n",
    "plt.imshow(sample_img_np)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "# Imagem pré-processada\n",
    "plt.subplot(2, 5, 2)\n",
    "plt.imshow(preprocessed_img_np)\n",
    "plt.title('Pré-processada (224x224)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Imagens aumentadas\n",
    "for i, aug_img_np in enumerate(augmented_imgs_np):\n",
    "    plt.subplot(2, 5, i+3)\n",
    "    plt.imshow(aug_img_np)\n",
    "    plt.title(f'Aumento #{i+1}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Definir transformações de pré-processamento normalizadas (para modelos pré-treinados)\n",
    "# Usando média e desvio padrão do ImageNet\n",
    "imagenet_normalize = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Aplicar normalização ImageNet\n",
    "normalized_img = imagenet_normalize(sample_img_tensor)\n",
    "\n",
    "# Não podemos visualizar diretamente a imagem normalizada (valores fora de [0,1])\n",
    "# Vamos desnormalizar\n",
    "denormalize = v2.Compose([\n",
    "    v2.Normalize(\n",
    "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "        std=[1/0.229, 1/0.224, 1/0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "denormalized_img = denormalize(normalized_img)\n",
    "denormalized_img_np = denormalized_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Visualizar imagem original e normalizada\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Imagem original\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(sample_img_np)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "# Imagem normalizada e depois desnormalizada\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.clip(denormalized_img_np, 0, 1))  # Clip para garantir valores no intervalo [0,1]\n",
    "plt.title('Normalizado -> Desnormalizado')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9c36b",
   "metadata": {},
   "source": [
    "## 6. Conclusões e Recomendações\n",
    "\n",
    "Com base na análise exploratória realizada, podemos extrair as seguintes conclusões e recomendações para o treinamento das redes neurais:\n",
    "\n",
    "### Principais Insights:\n",
    "\n",
    "1. **Distribuição de Classes:**\n",
    "   - O dataset pode apresentar desbalanceamento entre as classes, o que pode impactar o treinamento.\n",
    "   - Pode ser necessário utilizar técnicas como amostragem ponderada ou ajuste nos pesos da função de perda.\n",
    "\n",
    "2. **Características das Imagens:**\n",
    "   - As imagens possuem dimensões variadas, sendo necessário padronizar para um tamanho fixo.\n",
    "   - Algumas imagens são em escala de cinza e outras em RGB, sendo importante tratar essa heterogeneidade.\n",
    "   - A qualidade das imagens varia, com diferentes resoluções e formatos.\n",
    "\n",
    "3. **Pré-processamento Recomendado:**\n",
    "   - Redimensionar todas as imagens para 224x224 (padrão para muitas CNNs pré-treinadas).\n",
    "   - Converter todas as imagens para RGB (3 canais).\n",
    "   - Normalizar os valores de pixel usando as estatísticas do ImageNet para modelos pré-treinados.\n",
    "\n",
    "4. **Data Augmentation Recomendado:**\n",
    "   - Rotações leves (±15 graus) - apropriado para raios-X que mantêm seu significado mesmo com pequenas rotações.\n",
    "   - Pequenas translações (10% em cada direção).\n",
    "   - Ajustes de brilho e contraste (20% de variação) - simula diferentes condições de exposição dos raios-X.\n",
    "   - Cortes aleatórios preservando a escala - ajuda a focar em diferentes partes da imagem.\n",
    "   - Evitar espelhamento vertical, pois pode alterar características anatômicas importantes.\n",
    "\n",
    "5. **Considerações para o Treinamento:**\n",
    "   - Dividir adequadamente o conjunto de treino em treino e validação (por exemplo, 80/20).\n",
    "   - Monitorar cuidadosamente o overfitting, especialmente devido ao número limitado de amostras.\n",
    "   - Utilizar callbacks como Early Stopping para evitar overfitting.\n",
    "   - Considerar utilizar batch normalization nas redes customizadas para melhorar o treinamento.\n",
    "\n",
    "6. **Modelos Pré-treinados Recomendados:**\n",
    "   - DenseNet ou ResNet podem ser boas opções devido ao seu desempenho em tarefas médicas.\n",
    "   - MobileNetV2/V3 para aplicações que necessitam de menor carga computacional.\n",
    "\n",
    "### Próximos Passos:\n",
    "\n",
    "1. Implementar os pipelines de dados com as transformações adequadas.\n",
    "2. Desenvolver a CNN customizada com base nas características identificadas.\n",
    "3. Adaptar modelos pré-treinados para a tarefa específica.\n",
    "4. Treinar os modelos monitorando as métricas de desempenho.\n",
    "5. Realizar análise comparativa entre os diferentes modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RedesNeurais",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
